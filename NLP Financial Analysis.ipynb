{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NLP.csv\")\n",
    "name = [list(df.items())[0][1][i] for i in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"StopWords_GenericLong.txt\",header=None)\n",
    "stopwords = [i.lower() for i in df2.iloc[:,0]]\n",
    "\n",
    "df3 = pd.read_csv(\"MasterDictionary_2018.csv\",index_col=\"Word\")\n",
    "for i in df3.Negative:\n",
    "    if i>0:\n",
    "        df3.Negative.replace(i,1,inplace=True)\n",
    "for i in df3.Positive:\n",
    "    if i>0:\n",
    "        df3.Positive.replace(i,1,inplace=True)\n",
    "        \n",
    "df4 = pd.read_csv(\"uncertainty.csv\")\n",
    "uncertainty = [i.lower() for i in df4.iloc[:,0]]\n",
    "\n",
    "df5 = pd.read_csv(\"constraining.csv\")\n",
    "constraining = [i.lower() for i in df5.iloc[:,0]]\n",
    "\n",
    "Output = pd.read_csv(\"Output Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(data):\n",
    "    clean_text_1 = word_tokenize(str.lower(data))\n",
    "    clean_text_2 = []\n",
    "    for words in clean_text_1:\n",
    "        res1 = re.sub(r'[^\\w\\s]',\"\",words)\n",
    "        res = re.sub(r'[^\\D]',\"\",res1)\n",
    "        if res != \"\":\n",
    "            clean_text_2.append(res)\n",
    "    clean_text_3 = [i for i in clean_text_2 if i not in stopwords]\n",
    "    \n",
    "    Negative = []\n",
    "    Positive = []\n",
    "    Complex_Words = []\n",
    "    uncertainty_score = 0\n",
    "    constraining_score = 0\n",
    "    for i in clean_text_3:\n",
    "        if i.upper() in list(df3.index):\n",
    "            Negative.append(df3.loc[i.upper()][6])\n",
    "            Positive.append(df3.loc[i.upper()][7])\n",
    "            if df3.loc[i.upper()][16] > 2:\n",
    "                Complex_Words.append(i.upper())\n",
    "        if i in uncertainty:\n",
    "            uncertainty_score += 1\n",
    "        if i in constraining:\n",
    "            constraining_score += 1\n",
    "    \n",
    "    constraining_words_whole_report = 0\n",
    "    for i in clean_text_2:\n",
    "        if i in constraining:\n",
    "            constraining_words_whole_report += 1\n",
    "    \n",
    "    Positive_Score = sum(Positive)\n",
    "    Negative_Score = sum(Negative)\n",
    "    Word_Count = len(clean_text_3)\n",
    "    Complex_Word_Count = len(Complex_Words)\n",
    "    Polarity_Score = (Positive_Score - Negative_Score)/ ((Positive_Score + Negative_Score) + 0.000001)\n",
    "    Average_Sentence_Length = Word_Count/len(sent_tokenize(str.lower(d[n:])))\n",
    "    Percentage_of_Complex_words = Complex_Word_Count/Word_Count\n",
    "    Fog_Index = 0.4 * (Average_Sentence_Length + Percentage_of_Complex_words)\n",
    "    positive_word_proportion = Positive_Score/Word_Count\n",
    "    negative_word_proportion = Negative_Score/Word_Count\n",
    "    uncertainty_word_proportion = uncertainty_score/Word_Count\n",
    "    constraining_word_proportion = constraining_score/Word_Count\n",
    "\n",
    "    return [Positive_Score, Negative_Score,\n",
    "            Polarity_Score,Average_Sentence_Length,\n",
    "            Percentage_of_Complex_words,Fog_Index,Complex_Word_Count,Word_Count, \n",
    "            uncertainty_score,constraining_score,positive_word_proportion,negative_word_proportion, \n",
    "            uncertainty_word_proportion, constraining_word_proportion,constraining_words_whole_report]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Row: 66\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import Request, urlopen, HTTPError\n",
    "from time import sleep\n",
    "\n",
    "def get_url_data(url = \"\"):\n",
    "    try:\n",
    "        request = Request(url, headers = {'User-Agent' :\\\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36\"})\n",
    "\n",
    "        response = urlopen(request)\n",
    "        data = response.read().decode(\"utf8\")\n",
    "        return data\n",
    "    except HTTPError:\n",
    "        return None\n",
    "\n",
    "for i in range(len(name)):\n",
    "    url = \"https://www.sec.gov/Archives/\" + name[i]\n",
    "    try:\n",
    "        while True:\n",
    "            d = get_url_data(url)\n",
    "            if d != None:\n",
    "                print(\"Sheet Row: \" + str(i+2))\n",
    "                n = d.find(\"COMPANY DATA:\")\n",
    "                soup = BeautifulSoup(d[n:])\n",
    "                for script in soup([\"script\", \"style\"]):\n",
    "                    script.decompose()\n",
    "                strips = str(list(soup.stripped_strings))\n",
    "                output = sentiment(strips)\n",
    "                for j in range(len(output)):\n",
    "                    Output.iloc[i,j+6]  = output[j]\n",
    "                break\n",
    "    except:\n",
    "        print(\"Sheet Row: \" + str(i+2),\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output.to_csv(\"Final2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
